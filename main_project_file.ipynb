{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0qkFTVyQ1nFG"
      },
      "outputs": [],
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import (\n",
        "Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape,Input,Conv2D, Conv2DTranspose,LeakyReLU)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "import cv2 as cv\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SqueezeLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.squeeze(inputs, axis=0)  # Squeeze the batch dimension"
      ],
      "metadata": {
        "id": "-FcglBIqLYQV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape=(150,150,1)"
      ],
      "metadata": {
        "id": "fITGbt-31sP8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(input_shape):\n",
        " model = Sequential()\n",
        " model.add(Dense(150*150, input_dim=22500))\n",
        " model.add(Reshape((5,5, 900)))\n",
        " model.add(Conv2DTranspose(300, kernel_size=3, strides=3, padding='same'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(LeakyReLU(alpha=0.01))\n",
        " model.add(Conv2DTranspose(3, kernel_size=3, strides=10, padding='same'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(LeakyReLU(alpha=0.01))\n",
        " model.add(SqueezeLayer())\n",
        " return model"
      ],
      "metadata": {
        "id": "xAqXGkO-2N2g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv.imread('pic1.jpg')\n",
        "img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "img=cv.resize(img,(150,150))\n",
        "img=img.reshape(150,150,1)\n",
        "img=img.flatten()"
      ],
      "metadata": {
        "id": "tUywBmEL2Sky"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator=build_generator(img_shape)"
      ],
      "metadata": {
        "id": "3Y7o4IlC-aay",
        "outputId": "a04e28fd-0323-44b6-df91-1ff88cbc2f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape\n",
        "generator.summary()\n",
        "# out=model.predict(img)"
      ],
      "metadata": {
        "id": "pdReCbr3-qQK",
        "outputId": "d239c261-8b50-449a-a644-e87a9a7ff4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22500\u001b[0m)               │     \u001b[38;5;34m506,272,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m900\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_4 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │       \u001b[38;5;34m2,430,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │           \u001b[38;5;34m1,200\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_5 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │           \u001b[38;5;34m8,103\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │              \u001b[38;5;34m12\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ squeeze_layer_2 (\u001b[38;5;33mSqueezeLayer\u001b[0m)       │ (\u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22500</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">506,272,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">900</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,103</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ squeeze_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeLayer</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m508,712,115\u001b[0m (1.90 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">508,712,115</span> (1.90 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m508,711,509\u001b[0m (1.90 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">508,711,509</span> (1.90 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m606\u001b[0m (2.37 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">606</span> (2.37 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv.imread('pic1.jpg')\n",
        "img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n"
      ],
      "metadata": {
        "id": "K0nHpNNUhxwn"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv.resize(img,(150,150))"
      ],
      "metadata": {
        "id": "E2YayMG7h99w"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=img.reshape(150,150,1)\n",
        "img=img.flatten()"
      ],
      "metadata": {
        "id": "0hKI8sRrh8MS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=img[np.newaxis,:]\n"
      ],
      "metadata": {
        "id": "TsMUp-1Qh6OF"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "fhU1904Ki7Rq",
        "outputId": "c16fd4aa-fda5-4fff-dd04-bd059625b823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 22500)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        " model = Sequential()\n",
        " model.add(Conv2D(32,kernel_size=3,strides=2,input_shape=(150,150,3),padding='same'))\n",
        " model.add(LeakyReLU(alpha=0.01))\n",
        " model.add(Conv2D(64,kernel_size=3,strides=2,input_shape=(150,150,3),padding='same'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(LeakyReLU(alpha=0.01))\n",
        " model.add(Conv2D(128,kernel_size=3,strides=2,input_shape=(150,150,3),padding='same'))\n",
        " model.add(BatchNormalization())\n",
        " model.add(LeakyReLU(alpha=0.01))\n",
        " model.add(Flatten())\n",
        " model.add(Dense(1, activation='sigmoid'))\n",
        " return model"
      ],
      "metadata": {
        "id": "RsCHOwaOfkJ4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator, discriminator):\n",
        " model = Sequential()\n",
        " model.add(generator)\n",
        " model.add(discriminator)\n",
        " return model\n",
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "discriminator.trainable = False\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "metadata": {
        "id": "9Oa_41VCfuTL",
        "outputId": "2c55ebb4-15e3-41ae-d6e5-2e2ae7141faa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "losses = []\n",
        "accuracies = []\n",
        "iteration_checkpoints = []\n",
        "def train(iterations, batch_size, sample_interval):\n",
        " (X_train, _), (_, _) = mnist.load_data()\n",
        " X_train = X_train / 127.5 - 1.0\n",
        " X_train = np.expand_dims(X_train, axis=3)\n",
        " real = np.ones((batch_size, 1))\n",
        " fake = np.zeros((batch_size, 1))\n",
        " with tf.device('/GPU:0'):\n",
        "  for iteration in range(iterations):\n",
        "   idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "   imgs = X_train[idx]\n",
        "   z = np.random.normal(0, 1, (batch_size, 100))\n",
        "   gen_imgs = generator.predict(z,verbose=0)\n",
        "   d_loss_real = discriminator.train_on_batch(imgs, real)\n",
        "   d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "   d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake,)\n",
        "   z = np.random.normal(0, 1, (batch_size, 100))\n",
        "   gen_imgs = generator.predict(z,verbose=0)\n",
        "   g_loss = gan.train_on_batch(z, real)\n",
        "   if (iteration + 1) % sample_interval == 0:\n",
        "    losses.append((d_loss, g_loss))\n",
        "    accuracies.append(100.0 * accuracy)\n",
        "    iteration_checkpoints.append(iteration + 1)\n",
        "    print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "    (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n",
        "    sample_images(generator)"
      ],
      "metadata": {
        "id": "w7_IIrCdgczD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " (X_train, _), (_, _) = mnist.load_data()\n",
        "#  X_train = X_train / 127.5 - 1.0\n",
        "#  X_train = np.expand_dims(X_train, axis=3)"
      ],
      "metadata": {
        "id": "WP7-6BPrgxlM"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "dwSuOr35g3jF",
        "outputId": "4e8e1aad-f27b-4894-c6c9-c56f7e5d0009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "metadata": {
        "id": "5gk-p9nhhfUA",
        "outputId": "db7e6a7e-b376-46e4-a18d-78252173a881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d theblackmamba31/landscape-image-colorization\n"
      ],
      "metadata": {
        "id": "E_yslufOow6K",
        "outputId": "98f93c4f-7f89-4454-d63a-0e89e872d051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/theblackmamba31/landscape-image-colorization\n",
            "License(s): unknown\n",
            "landscape-image-colorization.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('landscape-image-colorization.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n"
      ],
      "metadata": {
        "id": "Nxuf_CaKpCxR"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_path_y = 'dataset/landscape Images/color'\n",
        "X=[]\n",
        "Y=[]\n",
        "for filename in os.listdir(image_path_y):\n",
        " img=cv.imread(os.path.join(image_path_y, filename))\n",
        " img=np.array(img)\n",
        " Y.append(img)"
      ],
      "metadata": {
        "id": "l8dx86pipZ5y"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_images_by_shape(image_list, target_shape=(150, 150, 3)):\n",
        "    filtered_images = []\n",
        "    for image in image_list:\n",
        "        if image.shape == target_shape:\n",
        "            filtered_images.append(image)\n",
        "    return filtered_images\n",
        "Y=filter_images_by_shape(Y)"
      ],
      "metadata": {
        "id": "3KxcmqX0xJFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y=np.array(Y)\n"
      ],
      "metadata": {
        "id": "qq-5ujcGxlpM"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "id": "zdRXc15XyK9j",
        "outputId": "89d38926-5936-4cbe-9195-5a317bb4f1f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7106, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for img in Y:\n",
        " img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        " img=np.array(img)\n",
        " img=img.reshape(150,150,1)\n",
        " X.append(img)"
      ],
      "metadata": {
        "id": "ubG-FPZWq4jU"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(X)\n"
      ],
      "metadata": {
        "id": "Xl0lDj6zskGQ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_normalized=X/255.0"
      ],
      "metadata": {
        "id": "qFllKRkat5tq"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_normalized=Y/255.0"
      ],
      "metadata": {
        "id": "iXBApyytyjF0"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "losses = []\n",
        "accuracies = []\n",
        "iteration_checkpoints = []\n",
        "def train(iterations, batch_size, sample_interval):\n",
        " (X_train, _), (_, _) = mnist.load_data()\n",
        " X_train = X_train / 127.5 - 1.0\n",
        " X_train = np.expand_dims(X_train, axis=3)\n",
        " real = np.ones((batch_size, 1))\n",
        " fake = np.zeros((batch_size, 1))\n",
        " with tf.device('/GPU:0'):\n",
        "  for iteration in range(iterations):\n",
        "   idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "   imgs = X_train[idx]\n",
        "   z = np.random.normal(0, 1, (batch_size, 100))\n",
        "   gen_imgs = generator.predict(z,verbose=0)\n",
        "   d_loss_real = discriminator.train_on_batch(imgs, real)\n",
        "   d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "   d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake,)\n",
        "   z = np.random.normal(0, 1, (batch_size, 100))\n",
        "   gen_imgs = generator.predict(z,verbose=0)\n",
        "   g_loss = gan.train_on_batch(z, real)\n",
        "   if (iteration + 1) % sample_interval == 0:\n",
        "    losses.append((d_loss, g_loss))\n",
        "    accuracies.append(100.0 * accuracy)\n",
        "    iteration_checkpoints.append(iteration + 1)\n",
        "    print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "    (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n",
        "    sample_images(generator)"
      ],
      "metadata": {
        "id": "jEl9-kT5sNid",
        "outputId": "bc330e93-0c4b-4475-f095-ca87901cc0bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 150, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}